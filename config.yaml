# Configuration file for Multi-Agent Research System
# You can modify these settings for their implementation

system:
  name: "Multi-Agent Research Assistant"
  topic: "Ethical AI in Education"  # Change this to your chosen topic
  max_iterations: 10
  timeout_seconds: 300
  max_turns: 8  # Maximum number of turns in RoundRobinGroupChat to prevent context length issues

agents:
  planner:
    role: "Task Planner"
    enabled: true
    # Custom system prompt (optional - leave empty to use default)
    # If provided, ensure it includes the handoff signal: "PLAN COMPLETE"
    system_prompt: |
      You are a research planner for Ethical AI in Education. Break down queries into actionable steps (150-200 words max).

      **You have NO tools** - only create plans. The Researcher handles all searching.

      Steps: 1) Analyze key concepts, 2) Determine source types (papers/web), 3) Suggest search queries/keywords, 4) Outline synthesis approach.

      Provide numbered steps covering: what to gather, why relevant, questions to answer. End with "PLAN COMPLETE".
    # Example custom prompt:
    # system_prompt: |
    #   You are an expert research planner specializing in HCI topics.
    #   Break down queries into specific, actionable research steps.
    #   Focus on recent publications (last 5 years) and seminal works.
    #   After creating the plan, say "PLAN COMPLETE".


  researcher:
    role: "Evidence Gatherer"
    enabled: true
    # Custom system prompt (optional - leave empty to use default)
    # If provided, ensure it mentions tools and includes: "RESEARCH COMPLETE"
    system_prompt: |
      Researcher for Ethical AI in Education. Gather credible info from papers and web (200-300 words max).

      **Tools work automatically** - describe what you need in natural language. No function calls.

      **Select ONLY top 8 sources**: Prioritize by relevance score (web) or citations/recency (papers). Summarize findings from selected sources only.

      Process: 1) Review plan, 2) State info needs (auto-searches), 3) Select 8 most relevant, 4) Extract key findings, 5) Note citation details.

      Prefer recent (3-5 years), peer-reviewed sources. End with "RESEARCH COMPLETE".
    max_sources: 10
    # Example custom prompt:
    # system_prompt: |
    #   You are a research specialist in HCI and UX design.
    #   Use web_search() and paper_search() tools to gather evidence.
    #   Prioritize peer-reviewed papers and authoritative sources.
    #   After collecting 8-10 sources, say "RESEARCH COMPLETE".

  writer:
    role: "Report Synthesizer"
    enabled: true
    # Custom system prompt (optional - leave empty to use default)
    # If provided, ensure it includes: "DRAFT COMPLETE"
    system_prompt: |
      Writer for Ethical AI in Education. Synthesize Researcher's findings into clear responses (400-600 words max).

      **Structure**: Brief intro → logical sections → APA citations → References. Paraphrase, don't copy. Answer the query directly.

      **Citation tools work automatically** - reference sources naturally (e.g., "Smith (2023) found..."). No function calls needed.

      **Revision**: If Critic says "NEEDS REVISION", address all feedback. If "APPROVED - RESEARCH COMPLETE", you're done.

      Use all sources from Researcher. Write clearly with defined technical terms.


  critic:
    role: "Quality Verifier"
    enabled: true
    # Custom system prompt (optional - leave empty to use default)
    # If provided, ensure it includes: "APPROVED - RESEARCH COMPLETE" or "NEEDS REVISION"
    system_prompt: |
      Peer reviewer for Ethical AI in Education. Evaluate Writer's output for quality, accuracy, completeness.

      **Criteria**: Relevance to query, credible/well-cited sources, completeness, accuracy, clarity, synthesis, appropriate length (400-600 words).

      **Review**: Check alignment with plan, verify citations, identify gaps/errors. Provide specific constructive feedback.

      **End with**: "APPROVED - RESEARCH COMPLETE" (if quality meets standards) OR "NEEDS REVISION" (if significant issues).
    # Example custom prompt:
    # system_prompt: |
    #   You are a peer reviewer for HCI research.
    #   Evaluate for academic rigor, source quality, and clarity.
    #   Be thorough but constructive in your feedback.
    #   Say "APPROVED - RESEARCH COMPLETE" or "NEEDS REVISION".

models:
  # Default model for agents (Groq)
  default:
    provider: "groq"
    name: "openai/gpt-oss-20b"
    temperature: 0.7
    max_tokens: 1500  # Reduced to help prevent context overflow

  # Judge model for evaluation
  judge:
    provider: "groq"
    name: "openai/gpt-oss-20b"  # Use same model as agents for consistency
    temperature: 0.3
    max_tokens: 2048  # Increased to prevent JSON truncation

tools:
  web_search:
    enabled: true
    provider: "tavily"  # or "brave"
    max_results: 5

  paper_search:
    enabled: true
    provider: "semantic_scholar"
    max_results: 10

  citation_extraction:
    enabled: true

safety:
  enabled: true
  framework: "guardrails"  # or "nemo_guardrails"
  log_events: true

  # Define prohibited categories
  prohibited_categories:
    - "harmful_content"
    - "personal_attacks"
    - "misinformation"
    - "off_topic_queries"

  # Response strategies per validator
  response_strategies:
    # Input validators
    input:
      toxic_language:
        action: "refuse"
        severity: "high"
        message: "I cannot process requests containing harmful or inappropriate language. Please rephrase your query in a respectful manner."

      detect_pii:
        action: "sanitize"
        severity: "high"
        message: "I've removed personally identifiable information from your query. Please resubmit without personal details."
        allow_sanitized: true

      prompt_injection:
        action: "refuse"
        severity: "high"
        message: "I cannot process this request. Please provide a clear research question related to Ethical AI in Education."

      off_topic:
        action: "redirect"
        severity: "medium"
        message: "This system specializes in research on 'Ethical AI in Education'. Could you please rephrase your query to focus on this topic?"

    # Output validators
    output:
      toxic_language:
        action: "sanitize"
        severity: "high"
        message: "The response has been sanitized to remove inappropriate content."
        fallback_to_refuse: true

      detect_pii:
        action: "sanitize"
        severity: "high"
        message: "Personal information has been redacted from the response."
        redaction_marker: "[REDACTED]"

      bias_check:
        action: "sanitize"
        severity: "medium"
        message: "The response has been reviewed and adjusted to reduce potential bias."
        warning_only: false

      factual_consistency:
        action: "refuse"
        severity: "high"
        message: "I cannot provide this response as it may contain inaccurate information. Please verify the sources."

    # Default fallback strategy
    default:
      action: "refuse"
      message: "I cannot process this request due to safety policies."

  # Legacy response strategies (kept for backward compatibility)
  on_violation:
    action: "refuse"  # or "sanitize" or "redirect"
    message: "I cannot process this request due to safety policies."

evaluation:
  enabled: true
  num_test_queries: 8
  test_queries_path: "data/test_queries.json"

  # Multiple judge perspectives - at least 2 independent judging prompts
  judges:
    - name: "comprehensive_rubric"
      description: "Comprehensive evaluation using detailed rubric covering all criteria"
      weight: 0.5

    - name: "ethical_expert"
      description: "Evaluation from ethical AI in education expert perspective"
      weight: 0.5

  # Judge criteria - detailed descriptions for Ethical AI in Education
  criteria:
    - name: "relevance_and_coverage"
      weight: 0.25
      description: |
        Relevance & Coverage: Does the response directly and comprehensively address the query?
        For Ethical AI in Education queries, this includes:
        - Addressing all key aspects of the ethical question
        - Covering relevant ethical principles, frameworks, or considerations
        - Connecting concepts to educational contexts specifically
        - Addressing stakeholder perspectives (students, educators, parents, institutions)
        - Including practical implications and real-world applications

    - name: "evidence_use_and_citation_quality"
      weight: 0.25
      description: |
        Evidence Use & Citation Quality: Are sources credible, relevant, and properly cited?
        For Ethical AI in Education, this includes:
        - Use of peer-reviewed academic sources on AI ethics, educational technology, or related fields
        - Citation of relevant policy documents, guidelines, or frameworks (e.g., UNESCO, IEEE, FERPA)
        - Proper APA-style citation formatting
        - Integration of evidence to support claims
        - Diversity of sources (academic, policy, case studies)
        - Recency of sources when relevant (especially for rapidly evolving AI field)

    - name: "factual_accuracy_and_consistency"
      weight: 0.20
      description: |
        Factual Accuracy & Consistency: Is the information correct and internally consistent?
        This includes:
        - Accurate representation of ethical principles, frameworks, and concepts
        - Correct references to regulations, policies, or standards (e.g., FERPA, COPPA)
        - Consistency in terminology and definitions throughout
        - No contradictory statements
        - Accurate representation of research findings or case studies
        - Proper understanding of technical concepts related to AI ethics

    - name: "safety_compliance"
      weight: 0.15
      description: |
        Safety Compliance: Does the response avoid unsafe or inappropriate content?
        For Ethical AI in Education, this includes:
        - No harmful, discriminatory, or biased content
        - No misinformation about AI capabilities or limitations
        - Appropriate handling of sensitive topics (student privacy, surveillance, etc.)
        - Balanced perspectives that don't promote harmful practices
        - Compliance with educational and ethical standards

    - name: "clarity_and_organization"
      weight: 0.15
      description: |
        Clarity & Organization: Is the response well-structured and easy to understand?
        This includes:
        - Clear introduction that addresses the query
        - Logical organization with clear sections or subsections
        - Smooth transitions between ideas
        - Appropriate use of headings, lists, or formatting
        - Clear, accessible language appropriate for the audience
        - Concise yet comprehensive coverage (500-800 words ideal)
        - Effective use of examples or case studies to illustrate points

logging:
  level: "INFO"
  file: "logs/system.log"
  safety_log: "logs/safety_events.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
